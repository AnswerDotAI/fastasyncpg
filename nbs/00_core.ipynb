{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c0b2492",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp core"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c90d9302",
   "metadata": {},
   "source": [
    "# fastasyncpg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a20356",
   "metadata": {},
   "source": [
    "`fastasyncpg` is a simple wrapper for asyncpg. We'll explain how it works and build up the module in a \"literate\" nbdev style."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9288fd",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80736074",
   "metadata": {},
   "source": [
    "On macOS, the recommended way to install PostgreSQL is via **Homebrew**. Other options include Postgres.app (a menubar app) and the EDB installer, but Homebrew integrates best with command-line workflows and makes updates simple.\n",
    "\n",
    "To install PostgreSQL 18 (the current latest stable release):\n",
    "\n",
    "```bash\n",
    "brew install postgresql@18\n",
    "```\n",
    "\n",
    "To check if you already have PostgreSQL installed via Homebrew, run `brew list | grep postgres`. You can also check which version is in your PATH with `psql --version`.\n",
    "\n",
    "Let's verify the installation is working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66516e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew list | grep postgres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb607a22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "psql (PostgreSQL) 18.1\n"
     ]
    }
   ],
   "source": [
    "!psql --version"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb730464",
   "metadata": {},
   "source": [
    "After installation, run `brew info postgresql@18` to see setup instructions. PostgreSQL 18 is \"keg-only\", meaning it's not automatically symlinked into your PATH.\n",
    "\n",
    "You'll see something like:\n",
    "\n",
    "```\n",
    "This formula has created a default database cluster with:\n",
    "  initdb --locale=en_US.UTF-8 -E UTF-8 /opt/homebrew/var/postgresql@18\n",
    "\n",
    "When uninstalling, some dead symlinks are left behind so you may want to run:\n",
    "  brew cleanup --prune-prefix\n",
    "\n",
    "postgresql@18 is keg-only, which means it was not symlinked into /opt/homebrew,\n",
    "because this is an alternate version of another formula.\n",
    "\n",
    "If you need to have postgresql@18 first in your PATH, run:\n",
    "  echo 'export PATH=\"/opt/homebrew/opt/postgresql@18/bin:$PATH\"' >> /Users/jhoward/.bash_profile\n",
    "\n",
    "To start postgresql@18 now and restart at login:\n",
    "  brew services start postgresql@18\n",
    "```\n",
    "\n",
    "The `brew info` output (above) tells you exactly what to do:\n",
    "\n",
    "1. **Add to PATH** (for bash): `echo 'export PATH=\"/opt/homebrew/opt/postgresql@18/bin:$PATH\"' >> ~/.bash_profile && source ~/.bash_profile`\n",
    "2. **Start the service**: `brew services start postgresql@18`\n",
    "\n",
    "This registers PostgreSQL to start automatically at login."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4c6662",
   "metadata": {},
   "source": [
    "To run non-interactive queries from a shell, use `-c` to pass a command directly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0063d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                        version                                        \n",
      "---------------------------------------------------------------------------------------\n",
      " PostgreSQL 18.1 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 15.2.1 20251112, 64-bit\n",
      "(1 row)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!psql -d postgres -c \"SELECT version();\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e47f7ad",
   "metadata": {},
   "source": [
    "Running `brew services start` registers PostgreSQL to start automatically at login/reboot. You can verify this with `brew services list`, which shows all Homebrew-managed services and their status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70d52ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "!brew services list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8ec3f5",
   "metadata": {},
   "source": [
    "To control auto-start behavior:\n",
    "- `brew services stop postgresql@18` — stop and disable auto-start\n",
    "- `brew services start postgresql@18` — start and enable auto-start  \n",
    "- `brew services run postgresql@18` — run once without enabling auto-start\n",
    "\n",
    "On Ubuntu, the standard way to get the latest PostgreSQL is through the **official PostgreSQL APT repository** (PGDG), since Ubuntu's default repos often have older versions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0007a7b3",
   "metadata": {},
   "source": [
    "## Connecting with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc0472e0",
   "metadata": {},
   "source": [
    "The most popular Python libraries for PostgreSQL are **psycopg2/psycopg3** (synchronous) and **asyncpg** (async). For async work, asyncpg is about 5x faster than psycopg3 and is the recommended choice.\n",
    "\n",
    "We'll use **asyncpg** for this wrapper — it's the fastest Python PostgreSQL library for async code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222d751e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from fastcore.utils import *\n",
    "import asyncpg\n",
    "from asyncpg import connection,protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ede6e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38724db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'natedawg'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user = os.environ['USER']; user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dcd60a",
   "metadata": {},
   "source": [
    "asyncpg uses `await` for all database operations. The `connect` function returns a connection object, and `fetchval` is a convenience method that returns a single value from the first row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb146d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PostgreSQL 18.1 on x86_64-pc-linux-gnu, compiled by gcc (GCC) 15.2.1 20251112, 64-bit'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = await asyncpg.connect(user=user, database='postgres', host='127.0.0.1')\n",
    "await conn.fetchval('SELECT version()')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df0734d",
   "metadata": {},
   "source": [
    "Let's create a simple test table to explore basic operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82347755",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE TABLE'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await conn.execute('''DROP TABLE IF EXISTS users''')\n",
    "await conn.execute('''CREATE TABLE users ( id SERIAL PRIMARY KEY, name TEXT NOT NULL, age INTEGER )''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a034a",
   "metadata": {},
   "source": [
    "Great! Now let's insert some data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7585b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'INSERT 0 1'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await conn.execute(\"INSERT INTO users (name, age) VALUES ($1, $2)\", 'Alice', 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b154e1",
   "metadata": {},
   "source": [
    "PostgreSQL uses `$1`, `$2`, etc. for parameterized queries, not `?` like SQLite. This syntax allows you to reference the same parameter multiple times and makes the order explicit.\n",
    "\n",
    "`fetch` returns a list of `Record` objects. Each record supports dict-like access by column name or index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db331ef8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record id=1 name='Alice' age=30>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = await conn.fetch(\"SELECT * FROM users\")\n",
    "rs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60b1d412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, asyncpg.protocol.record.Record)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r = rs[0]\n",
    "type(rs),type(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d2321f",
   "metadata": {},
   "source": [
    "`asyncpg.Record` objects use dict-like access (`r['name']` or `r[0]`), not attribute access. You can use `dict2obj` if you want the latter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aead35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Alice'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ro = dict2obj(dict(r))\n",
    "ro.name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4abacdb",
   "metadata": {},
   "source": [
    "Unlike psycopg2, asyncpg doesn't use traditional cursors. Instead, use `async for record in conn.cursor(...)` to iterate over results. However, cursors in asyncpg require an explicit transaction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14d9dca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raises \"NoActiveSQLTransactionError: cursor cannot be created outside of a transaction\"\n",
    "# async for record in conn.cursor(\"SELECT * FROM users\"): print(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d46d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Record id=1 name='Alice' age=30>\n"
     ]
    }
   ],
   "source": [
    "async with conn.transaction():\n",
    "    async for record in conn.cursor(\"SELECT * FROM users\"): print(record)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2e2023",
   "metadata": {},
   "source": [
    "By default, asyncpg operates in **auto-commit mode** — changes are applied immediately when not in an explicit transaction block. Regular queries (`execute`, `fetch`, etc.) don't need transactions, but cursors do. This is a direct reflection of how PostgreSQL itself handles \"portals\" (the underlying mechanism for cursors).\n",
    "\n",
    "In PostgreSQL, a portal is generally only valid for the duration of a transaction. If a transaction isn't explicitly started, PostgreSQL runs each command in its own \"one-shot\" transaction. For a cursor to stay open so you can fetch multiple batches of rows, the transaction it belongs to must remain open.\n",
    "\n",
    "Other libraries (like `psycopg2`) often hide this by starting a transaction for you automatically when you create a cursor, whereas `asyncpg` chooses to be more \"explicit\" about the underlying database state."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecb70dd",
   "metadata": {},
   "source": [
    "## Chinook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f1218c6",
   "metadata": {},
   "source": [
    "For testing with a real dataset, we'll use the **Chinook** sample database, which has tables for artists, albums, tracks, etc. The PostgreSQL version is available on GitHub:\n",
    "\n",
    "```bash\n",
    "curl -L -O https://github.com/lerocha/chinook-database/raw/master/ChinookDatabase/DataSources/Chinook_PostgreSql.sql\n",
    "```\n",
    "\n",
    "Now we need to create a database and run that script. First, let's create a database called `chinook`:\n",
    "\n",
    "```bash\n",
    "createdb chinook\n",
    "```\n",
    "\n",
    "Then we can load the SQL file into it:\n",
    "\n",
    "```bash\n",
    "psql -d chinook -f Chinook_PostgreSql.sql\n",
    "```\n",
    "\n",
    "Always close connections when done — this releases the database connection back to PostgreSQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8005ee76",
   "metadata": {},
   "outputs": [],
   "source": [
    "await conn.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab223ad",
   "metadata": {},
   "source": [
    "Now let's connect to the Chinook database to work with more realistic data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35863303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "275"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn = await asyncpg.connect(user=user, database='chinook', host='127.0.0.1')\n",
    "await conn.fetchval(\"SELECT count(*) FROM artist\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f4d039",
   "metadata": {},
   "source": [
    "## Metadata"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2448445",
   "metadata": {},
   "source": [
    "`Results` is a simple list subclass that renders as an HTML table in notebooks. It displays all rows with column headers, making query results easy to read:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb9cd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Results(list):\n",
    "    def _repr_html_(self):\n",
    "        if not self: return \"\"\n",
    "        ks = list(self[0].keys())\n",
    "        ths = \"\".join(f\"<th>{k}</th>\" for k in ks)\n",
    "        trs = \"\".join(f\"<tr>{''.join(f'<td>{v}</td>' for v in r.values())}</tr>\" for r in self)\n",
    "        return f'<table class=\"prose\"><thead><tr>{ths}</tr></thead><tbody>{trs}</tbody></table>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ddf7786",
   "metadata": {},
   "source": [
    "`sql` is a quick helper to run SQL and return results as a list of records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4c4cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.magic import register_cell_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a6d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@register_cell_magic\n",
    "async def sql(l,c): return Results(await conn.fetch(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9190723",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"prose\"><thead><tr><th>column_name</th><th>data_type</th><th>is_nullable</th></tr></thead><tbody><tr><td>artist_id</td><td>integer</td><td>NO</td></tr><tr><td>name</td><td>character varying</td><td>YES</td></tr></tbody></table>"
      ],
      "text/plain": [
       "[<Record column_name='artist_id' data_type='integer' is_nullable='NO'>,\n",
       " <Record column_name='name' data_type='character varying' is_nullable='YES'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT column_name, data_type, is_nullable\n",
    "FROM information_schema.columns\n",
    "WHERE table_name = 'artist' "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bbfe1e",
   "metadata": {},
   "source": [
    "In PostgreSQL, every table belongs to a **schema** — think of it as a folder or namespace. The default schema is `public`. When you create a table without specifying a schema, it lands there. You can query schema information via `information_schema` views:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "246560ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"prose\"><thead><tr><th>column_name</th><th>data_type</th><th>is_nullable</th></tr></thead><tbody><tr><td>artist_id</td><td>integer</td><td>NO</td></tr><tr><td>name</td><td>character varying</td><td>YES</td></tr></tbody></table>"
      ],
      "text/plain": [
       "[<Record column_name='artist_id' data_type='integer' is_nullable='NO'>,\n",
       " <Record column_name='name' data_type='character varying' is_nullable='YES'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%sql\n",
    "SELECT column_name, data_type, is_nullable\n",
    "FROM information_schema.columns\n",
    "WHERE table_name = 'artist'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb0690f",
   "metadata": {},
   "source": [
    "To list all tables in the `public` schema, you can query the `information_schema.tables` view:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08081d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Record table_name='artist'>,\n",
       " <Record table_name='album'>,\n",
       " <Record table_name='employee'>,\n",
       " <Record table_name='customer'>,\n",
       " <Record table_name='invoice'>,\n",
       " <Record table_name='invoice_line'>,\n",
       " <Record table_name='track'>,\n",
       " <Record table_name='playlist'>,\n",
       " <Record table_name='playlist_track'>,\n",
       " <Record table_name='genre'>,\n",
       " <Record table_name='media_type'>,\n",
       " <Record table_name='cat'>,\n",
       " <Record table_name='dog'>,\n",
       " <Record table_name='toy'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await conn.fetch(\"SELECT table_name FROM information_schema.tables WHERE table_schema = 'public'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79335f40",
   "metadata": {},
   "source": [
    "To customize how records behave, we need access to the underlying `Record` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f59343",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from asyncpg.protocol.record import Record"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860ed98d",
   "metadata": {},
   "source": [
    "`FRecord` extends asyncpg's `Record` with two conveniences: attribute access (`r.name` instead of `r['name']`) and HTML rendering for notebooks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9a012cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FRecord(Record):\n",
    "    def __getattr__(self, k):\n",
    "        if k.startswith('_'): raise AttributeError(k)\n",
    "        return self[k]\n",
    "\n",
    "    def _repr_html_(self):\n",
    "        rows = \"\".join(f\"<tr><td>{k}</td><td>{v}</td></tr>\" for k,v in self.items())\n",
    "        return f'<table class=\"prose\"><thead><tr><th>Field</th><th>Value</th></tr></thead><tbody>{rows}</tbody></table>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a8820c",
   "metadata": {},
   "source": [
    "We can use `record_class` to auto-wrap with `FRecord`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95964ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "await conn.close()\n",
    "\n",
    "conn = await asyncpg.connect(user=user, database='chinook', host='127.0.0.1', record_class=FRecord)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb20fcb1",
   "metadata": {},
   "source": [
    "`table_names` and `view_names` query PostgreSQL's system catalogs to list tables and views in a schema. We use `pg_class` and `pg_namespace` rather than `information_schema` for better performance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c604795",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def table_names(conn, schema='public'):\n",
    "    \"List of table names in `schema`\"\n",
    "    res = await conn.fetch(\"\"\"\n",
    "        SELECT c.relname FROM pg_class c\n",
    "        JOIN pg_namespace n ON n.oid = c.relnamespace\n",
    "        WHERE n.nspname = $1 AND c.relkind = 'r' AND NOT c.relname LIKE 'pg_%'\"\"\", schema)\n",
    "    return [r['relname'] for r in res]\n",
    "\n",
    "async def view_names(conn, schema='public'):\n",
    "    \"List of view names in `schema`\"\n",
    "    res = await conn.fetch(\"\"\"\n",
    "        SELECT c.relname FROM pg_class c\n",
    "        JOIN pg_namespace n ON n.oid = c.relnamespace\n",
    "        WHERE n.nspname = $1 AND c.relkind = 'v'\"\"\", schema)\n",
    "    return [r['relname'] for r in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6046cc78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist album employee customer invoice invoice_line track playlist playlist_track genre media_type cat dog toy\n"
     ]
    }
   ],
   "source": [
    "print(' '.join(await table_names(conn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5a5705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await view_names(conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d88d8f",
   "metadata": {},
   "source": [
    "`columns_info` returns a dict mapping column names to their PostgreSQL data types. It queries `pg_attribute` directly for efficiency:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29cf6d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def columns_info(conn, table, schema='public'):\n",
    "    \"Dict mapping column names to data types for `table`\"\n",
    "    res = await conn.fetch(\"\"\"\n",
    "        SELECT a.attname, format_type(a.atttypid, a.atttypmod) as data_type\n",
    "        FROM pg_attribute a\n",
    "        JOIN pg_class c ON c.oid = a.attrelid\n",
    "        JOIN pg_namespace n ON n.oid = c.relnamespace\n",
    "        WHERE n.nspname = $1 AND c.relname = $2 AND a.attnum > 0 AND NOT a.attisdropped\n",
    "        ORDER BY a.attnum\"\"\", schema, table)\n",
    "    return {r['attname']: r['data_type'] for r in res}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91b10d5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist_id', 'name']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(await columns_info(conn, 'artist'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "683671f1",
   "metadata": {},
   "source": [
    "We'll need to know each table's primary key. PostgreSQL stores this in `pg_index`. The `::regclass` cast is idiomatic PostgreSQL — it converts a table name string to its internal object ID, automatically handling schema resolution. The `indisprimary` flag identifies the primary key index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504a98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def pk_cols(conn, table):\n",
    "    \"Get primary key column(s) for `table`\"\n",
    "    res = await conn.fetch(\"\"\"\n",
    "        SELECT a.attname FROM pg_index i\n",
    "        JOIN pg_attribute a ON a.attrelid = i.indrelid AND a.attnum = ANY(i.indkey)\n",
    "        WHERE i.indrelid = $1::regclass AND i.indisprimary\"\"\", table)\n",
    "    return [r['attname'] for r in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d0f75f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist_id']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await pk_cols(conn, 'artist')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ac7f8c",
   "metadata": {},
   "source": [
    "`Database` wraps an asyncpg connection (or pool) and provides table/view metadata caching. It delegates unknown attributes to the underlying connection via `__getattr__`, so you can call `db.fetch(...)` directly. The `t` property returns a `_TablesGetter` for convenient table access."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350e6168",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Database:\n",
    "    def __init__(self, conn, refresh=True):\n",
    "        self.conn = conn\n",
    "        self._tnames,self._vnames = [],[]\n",
    "        self._tables = {}\n",
    "        if refresh: asyncio.create_task(self.refresh())\n",
    "\n",
    "    @property\n",
    "    def t(self):\n",
    "        if not hasattr(self, '_t'): self._t = _TablesGetter(self)\n",
    "        return self._t\n",
    "\n",
    "    def __getattr__(self, k): return getattr(self.conn, k)\n",
    "\n",
    "    def table(self, name):\n",
    "        if name not in self._tables: self._tables[name] = Table(self, name)\n",
    "        return self._tables[name]\n",
    "\n",
    "    async def refresh(self):\n",
    "        \"Refresh all metadata\"\n",
    "        self._tnames,self._vnames = await table_names(self),await view_names(self)\n",
    "        self._cols = {o: (await columns_info(self, o)) for o in self._tnames+self._vnames}\n",
    "        self._pks = {o: (await pk_cols(self, o)) for o in self._tnames}\n",
    "    \n",
    "    def __str__(self):\n",
    "        if isinstance(self.conn, asyncpg.pool.Pool):\n",
    "            kw = self.conn._connect_kwargs\n",
    "            u,h,d,p = kw.get('user','postgres'), kw.get('host','localhost'), kw.get('database','postgres'), kw.get('port',5432)\n",
    "        else:\n",
    "            pr,a = self.conn._params, self.conn._addr\n",
    "            u,h,d,p = pr.user, a[0], pr.database, a[1]\n",
    "        return f\"postgresql://{u}@{h}:{p}/{d}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e362e5f",
   "metadata": {},
   "source": [
    "`Table` represents a database table with metadata like columns and primary keys. The `xtra` method lets you set persistent row filters (useful for multi-tenancy). Tables stringify as quoted identifiers for safe SQL interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae461a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class Table:\n",
    "    def __init__(self, db, name):\n",
    "        store_attr()\n",
    "        self.xtra_id = {}\n",
    "\n",
    "    @property\n",
    "    def cols(self): return self.db._cols.get(self.name, {})\n",
    "    def __repr__(self): return f'Table \"{self.name}\"'\n",
    "    def __str__(self): return f'\"{self.name}\"'\n",
    "\n",
    "    def xtra(self, **kwargs):\n",
    "        \"Set extra constraints for queries/inserts\"\n",
    "        self.xtra_id = kwargs\n",
    "        return self\n",
    "\n",
    "    @property\n",
    "    def pks(self): return self.db._pks.get(self.name, [])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f3d902",
   "metadata": {},
   "source": [
    "`_Getter` is a base class for \"magic accessor\" objects that provide multiple ways to access items — by attribute (`dt.artist`), by index (`dt['artist']`), or by iteration (`for t in dt`). It implements `__dir__` so tab-completion works in notebooks, `__repr__` for nice display, `__contains__` for `in` checks, and both `__getattr__` and `__getitem__` for flexible access.\n",
    "\n",
    "`_TablesGetter` specializes this for tables, reading from the database's `_tnames` list. The `db.t` property returns one of these, giving you a clean API: `db.t.artist` instead of `db.table('artist')`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0374b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class _Getter:\n",
    "    def __init__(self, db, attr): self.db,self.attr = db,attr\n",
    "\n",
    "    def __repr__(self): return \", \".join(getattr(self.db, self.attr))\n",
    "    def __dir__(self): return getattr(self.db, self.attr)\n",
    "    def __iter__(self): return iter(self[dir(self)])\n",
    "    def __contains__(self, s): return (s if isinstance(s,str) else s.name) in dir(self)\n",
    "    def __getitem__(self, idxs):\n",
    "        if isinstance(idxs,str): return self.db.table(idxs)\n",
    "        return [self.db.table(o) for o in idxs]\n",
    "    def __getattr__(self, k):\n",
    "        if k.startswith('_'): raise AttributeError\n",
    "        return self.db.table(k)\n",
    "\n",
    "class _TablesGetter(_Getter):\n",
    "    def __init__(self, db): super().__init__(db,'_tnames')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f28a48d",
   "metadata": {},
   "source": [
    "`connect` is our main entry point — it creates an asyncpg connection with `FRecord` as the default record class, sets up JSON codecs, and returns a `Database` wrapper with metadata already loaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cceb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def connect(*args, **kwargs):\n",
    "    kwargs.setdefault('record_class', FRecord)\n",
    "    conn = await asyncpg.connect(*args, **kwargs)\n",
    "    res = Database(conn, refresh=False)\n",
    "    await res.refresh()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78235ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql://natedawg@127.0.0.1:5432/chinook'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await conn.close()\n",
    "\n",
    "db = await connect(user=user, database='chinook', host='127.0.0.1'); str(db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3684bb5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table \"artist\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = db.t\n",
    "artist = dt.artist\n",
    "artist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835200a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['artist_id']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist.pks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc498b7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Table \"album\", Table \"artist\"]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt['album','artist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df24eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"album\"\n",
      "\"artist\"\n"
     ]
    }
   ],
   "source": [
    "for tbl in dt:\n",
    "    if tbl.name[0]=='a': print(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850cdd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'artist' in dt\n",
    "assert artist in dt\n",
    "assert 'foo' not in dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a7cd37d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'artist_id': 'integer', 'name': 'character varying(120)'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist.cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c7285e",
   "metadata": {},
   "source": [
    "`_Col` represents a single column, with `__str__` returning fully-qualified SQL (`\"table\".\"column\"`). `_ColsGetter` follows the same pattern as `_TablesGetter` — it's a magic accessor that lets you write `artist.c.name` to get a column reference. The `__call__` method returns all columns as `_Col` objects, useful for building queries programmatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699ea455",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class _Col:\n",
    "    def __init__(self, t, c): self.t,self.c = t,c\n",
    "    def __str__(self):  return f'\"{self.t}\".\"{self.c}\"'\n",
    "    def __repr__(self):  return self.c\n",
    "    def __iter__(self): return iter(self.c)\n",
    "\n",
    "class _ColsGetter:\n",
    "    def __init__(self, tbl): self.tbl = tbl\n",
    "    def __dir__(self): return list(self.tbl.cols)\n",
    "    def __repr__(self): return \", \".join(dir(self))\n",
    "    def __call__(self): return [_Col(self.tbl.name,o.name) for o in self.tbl.columns]\n",
    "    def __contains__(self, s): return (s if isinstance(s,str) else s.c) in self.tbl.cols\n",
    "    def __getattr__(self, k):\n",
    "        if k[0]=='_': raise AttributeError\n",
    "        return _Col(self.tbl.name, k)\n",
    "\n",
    "@patch(as_prop=True)\n",
    "def c(self:Table): return _ColsGetter(self)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8f29cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist_id, name"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ac = artist.c\n",
    "ac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86dd9a3",
   "metadata": {},
   "source": [
    "Columns stringify in a format suitable for including in SQL statements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d620143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select \"artist\".\"name\" ...\n"
     ]
    }
   ],
   "source": [
    "print(f\"select {ac.name} ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "761341bf",
   "metadata": {},
   "source": [
    "Tables and views do the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a21d318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "select \"artist\".\"Name\" from \"artist\"\n"
     ]
    }
   ],
   "source": [
    "print(f\"select {ac.Name} from {artist}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9c464a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 'name' in ac\n",
    "assert ac.name in ac\n",
    "assert 'foo' not in ac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f15d8473",
   "metadata": {},
   "source": [
    "## Queries and views"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6246fa46",
   "metadata": {},
   "source": [
    "`db.q` is a convenience method that runs a SQL query and wraps results in a `Results` list for nice HTML rendering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "891dcd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def q(self:Database, sql, *args): return Results(await self.fetch(sql, *args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8b2bda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"prose\"><thead><tr><th>artist_id</th><th>name</th></tr></thead><tbody><tr><td>1</td><td>AC/DC</td></tr><tr><td>2</td><td>Accept</td></tr></tbody></table>"
      ],
      "text/plain": [
       "[<FRecord artist_id=1 name='AC/DC'>, <FRecord artist_id=2 name='Accept'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await db.q(f\"select * from {artist} limit 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13beff3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"prose\"><thead><tr><th>artist_id</th><th>name</th></tr></thead><tbody><tr><td>1</td><td>AC/DC</td></tr></tbody></table>"
      ],
      "text/plain": [
       "[<FRecord artist_id=1 name='AC/DC'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acdc = await db.q(f\"select * from {artist} where {ac.name} like 'AC/%'\")\n",
    "acdc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed17dd3",
   "metadata": {},
   "source": [
    "## Dataclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c924762",
   "metadata": {},
   "source": [
    "PostgreSQL has many data types that map to Python equivalents. We'll import the Python types we need:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc7310b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from decimal import Decimal\n",
    "from uuid import UUID\n",
    "from ipaddress import IPv4Network, IPv6Network, IPv4Interface, IPv6Interface, IPv4Address, IPv6Address\n",
    "from asyncpg.types import Range, BitString, Box, Circle, Line, LineSegment, Path, Point, Polygon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d4c7ab",
   "metadata": {},
   "source": [
    "`get_typ` extracts the base PostgreSQL type (stripping size specifiers like `(120)`) and maps it to the corresponding Python type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a559e812",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_typ(pg_type):\n",
    "    \"Get Python type for PostgreSQL type string\"\n",
    "    return pg_to_py[pg_type.split('(')[0].strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0117b9c",
   "metadata": {},
   "source": [
    "The `pg_to_py` dict maps PostgreSQL type names to Python types. This covers the most common types — numeric, string, temporal, JSON, network, and geometric:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a17706fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "pg_to_py = {\n",
    "    'smallint': int, 'integer': int, 'bigint': int,\n",
    "    'real': float, 'float': float, 'double precision': float,\n",
    "    'numeric': Decimal, 'decimal': Decimal,\n",
    "    \n",
    "    'char': str, 'character': str, 'name': str, 'varchar': str, 'character varying': str, 'text': str, 'xml': str,\n",
    "    'bytea': bytes,\n",
    "    'boolean': bool, 'bool': bool,\n",
    "    \n",
    "    'date': date,\n",
    "    'time': time, 'time without time zone': time, 'time with time zone': time,\n",
    "    'timestamp': datetime, 'timestamp without time zone': datetime, 'timestamp with time zone': datetime,\n",
    "    'interval': timedelta,\n",
    "    \n",
    "    'uuid': UUID,\n",
    "    'json': dict, 'jsonb': dict,\n",
    "    'money': str,\n",
    "    'macaddr': str,\n",
    "    \n",
    "    'cidr': IPv4Network, 'inet': IPv4Interface,\n",
    "    \n",
    "    'bit': BitString, 'varbit': BitString,\n",
    "    'box': Box, 'circle': Circle, 'line': Line, 'lseg': LineSegment,\n",
    "    'path': Path, 'point': Point, 'polygon': Polygon,\n",
    "    \n",
    "    'anyarray': list, 'ARRAY': list,\n",
    "    'anyrange': Range,\n",
    "    'record': tuple, 'tid': tuple,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ac7509",
   "metadata": {},
   "source": [
    "asyncpg doesn't automatically decode JSON columns — we need to register custom codecs. The `setup_json` function configures both `json` and `jsonb` types to use Python's `json` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c571d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9282bec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def setup_json(conn):\n",
    "    await conn.set_type_codec('json', encoder=json.dumps, decoder=json.loads, schema='pg_catalog')\n",
    "    await conn.set_type_codec('jsonb', encoder=json.dumps, decoder=json.loads, schema='pg_catalog')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15f439c",
   "metadata": {},
   "source": [
    "We'll re-define `connect` to use json now:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ad25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def connect(*args, **kwargs):\n",
    "    kwargs.setdefault('record_class', FRecord)\n",
    "    conn = await asyncpg.connect(*args, **kwargs)\n",
    "    await setup_json(conn)\n",
    "    res = Database(conn, refresh=False)\n",
    "    await res.refresh()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a86087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "await db.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01ae26b",
   "metadata": {},
   "outputs": [],
   "source": [
    "db = await connect(user=user, database='chinook', host='127.0.0.1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c32b4e",
   "metadata": {},
   "source": [
    "We'll use Python's `dataclasses` module to auto-generate typed classes from table schemas:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341b22b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import dataclass, field, make_dataclass, fields, Field, is_dataclass, MISSING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695a2170",
   "metadata": {},
   "source": [
    "With the type mapping in place, we can auto-generate Python dataclasses from table schemas. The `_get_flds` helper extracts field definitions, and `dataclass()` creates a dataclass matching the table structure. We use `flexiclass` from fastcore to make the dataclass more flexible (allowing partial instantiation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8402e3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _get_flds(tbl): \n",
    "    return [(k, get_typ(v)|None, field(default=UNSET))\n",
    "            for k,v in tbl.cols.items()]\n",
    "\n",
    "def _dataclass(self:Table, store=True, suf='')->type:\n",
    "    \"Create a `dataclass` with the types and defaults of this table\"\n",
    "    res = make_dataclass(self.name.title()+suf, _get_flds(self))\n",
    "    flexiclass(res)\n",
    "    if store: self.cls = res\n",
    "    return res\n",
    "\n",
    "Table.dataclass = _dataclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39c1ed7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist(artist_id=1, name='AC/DC')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt = db.t\n",
    "artist = dt.artist\n",
    "\n",
    "Artist = artist.dataclass()\n",
    "art1_obj = Artist(**acdc[0])\n",
    "art1_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b863927a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.Artist"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist.cls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "131b827e",
   "metadata": {},
   "source": [
    "You can get the definition of the dataclass using fastcore's `dataclass_src`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50f7c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```python\n",
       "@dataclass\n",
       "class Artist:\n",
       "    artist_id: int | None = UNSET\n",
       "    name: str | None = UNSET\n",
       "\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = dataclass_src(Artist)\n",
    "hl_md(src, 'python')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b30193",
   "metadata": {},
   "source": [
    "`all_dcs` generates dataclasses for every table (and optionally views) in the database. This is useful for type-checking and IDE autocompletion:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf91a162",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def all_dcs(db, with_views=False, store=True, suf=''):\n",
    "    \"dataclasses for all objects in `db`\"\n",
    "    return [o.dataclass(store=store, suf=suf) for o in list(db.t) + (db.views if with_views else [])]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc5fe6c",
   "metadata": {},
   "source": [
    "## get"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf658fe",
   "metadata": {},
   "source": [
    "The `xtra` method (defined earlier) lets you set persistent filters on a table. The `_add_xtra` helper injects these constraints into WHERE clauses. This is useful for multi-tenant apps or any situation where you want automatic row filtering — e.g., `album.xtra(artist_id=1)` ensures all subsequent queries only see albums by artist 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b37f834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _add_xtra(tbl, where, args, offset=0):\n",
    "    if not tbl.xtra_id: return where, args\n",
    "    args = list(args)\n",
    "    xw = ' AND '.join(f'\"{k}\"=${len(args)+offset+i+1}' for i,k in enumerate(tbl.xtra_id))\n",
    "    where = f'({where}) AND {xw}' if where else xw\n",
    "    args.extend(tbl.xtra_id.values())\n",
    "    return where, args"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1504d94e",
   "metadata": {},
   "source": [
    "`__getitem__` provides dict-style access by primary key. It raises `NotFoundError` if the row doesn't exist (or doesn't match `xtra` constraints). If a dataclass has been generated for the table, results are automatically converted to that type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de5874df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class NotFoundError(Exception): pass\n",
    "\n",
    "@patch\n",
    "async def __getitem__(self:Table, pk):\n",
    "    \"Get row by primary key, raising NotFoundError if missing\"\n",
    "    if not self.pks: raise ValueError(f\"No primary key for {self.name}\")\n",
    "    where, args = _add_xtra(self, f'\"{self.pks[0]}\" = $1', [pk])\n",
    "    res = await self.db.fetch(f'SELECT * FROM {self} WHERE {where}', *args)\n",
    "    if not res: raise NotFoundError(f\"{self.name}[{pk}]\")\n",
    "    return self.cls(**res[0]) if hasattr(self, 'cls') else res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202afd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist(artist_id=1, name='AC/DC')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await artist[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ffa020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Album 1: Album(album_id=1, title='For Those About To Rock We Salute You', artist_id=1)\n",
      "Artist ID of album 1: 1\n",
      "\n",
      "With xtra(artist_id=1):\n",
      "Album 1: Album(album_id=1, title='For Those About To Rock We Salute You', artist_id=1)\n",
      "Error correctly raised: <class '__main__.NotFoundError'>\n"
     ]
    }
   ],
   "source": [
    "album = dt.album\n",
    "Album = album.dataclass()\n",
    "\n",
    "print(\"Album 1:\", await album[1])\n",
    "print(\"Artist ID of album 1:\", (await album[1]).artist_id)\n",
    "\n",
    "album.xtra(artist_id=1)\n",
    "print(\"\\nWith xtra(artist_id=1):\")\n",
    "print(\"Album 1:\", await album[1])  # Should work - album 1 is by artist 1\n",
    "\n",
    "try: await album[2]  # Album 2 is by a different artist\n",
    "except NotFoundError as e: print('Error correctly raised:', type(e))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7ac4a88",
   "metadata": {},
   "source": [
    "`get` is the \"safe\" version of `__getitem__` — it returns `None` instead of raising an exception when a row isn't found. This mirrors the pattern in fastlite and Python's `dict.get()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76a582ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def get(self:Table, pk):\n",
    "    \"Get row by primary key, or None if missing\"\n",
    "    try: return await self[pk]\n",
    "    except NotFoundError: return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "641fdad5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Artist(artist_id=1, name='AC/DC')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await artist.get(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e8e9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "await artist.get(99999)  # Should return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfe02a6",
   "metadata": {},
   "source": [
    "## call/select"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "574a0b0b",
   "metadata": {},
   "source": [
    "`rows_where` is the core query method. It builds SQL from its parameters, applies `xtra` constraints, and optionally converts results to the table's dataclass. Unlike psycopg2/sqlite which use `?` placeholders, PostgreSQL uses `$1, $2` positional parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2d38a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def rows_where(self:Table, where=None, where_args=None, order_by=None, select='*', limit=None, offset=None,\n",
    "    as_cls=True, debug=False):\n",
    "    \"Iterate over rows matching where clause\"\n",
    "    where, args = _add_xtra(self, where, where_args or [])\n",
    "    sql = f'SELECT {select} FROM {self}'\n",
    "    if where: sql += f' WHERE {where}'\n",
    "    if order_by: sql += f' ORDER BY {order_by}'\n",
    "    if limit: sql += f' LIMIT {limit}'\n",
    "    if offset: sql += f' OFFSET {offset}'\n",
    "    if debug: print(sql)\n",
    "    res = await self.db.fetch(sql, *args)\n",
    "    if as_cls and hasattr(self, 'cls'): res = [self.cls(**r) for r in res]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f687fb9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Artist(artist_id=1, name='AC/DC'),\n",
       " Artist(artist_id=2, name='Accept'),\n",
       " Artist(artist_id=3, name='Aerosmith')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await artist.rows_where(limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c8036e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Album(album_id=1, title='For Those About To Rock We Salute You', artist_id=1),\n",
       " Album(album_id=4, title='Let There Be Rock', artist_id=1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album.xtra(artist_id=1)\n",
    "await album.rows_where(limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74e02336",
   "metadata": {},
   "source": [
    "`count` is an async property that returns the number of rows in a table. It respects `xtra` constraints, so if you've set filters, only matching rows are counted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481230b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch(as_prop=True)\n",
    "async def count(self:Table):\n",
    "    where, args = _add_xtra(self, None, [])\n",
    "    sql = f'SELECT COUNT(*) FROM {self}'\n",
    "    if where: sql += f' WHERE {where}'\n",
    "    return await self.db.fetchval(sql, *args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc81515",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album.xtra(artist_id=1)\n",
    "await album.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8875e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "347"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album.xtra()\n",
    "await album.count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28682469",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from collections.abc import Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45fc8e4",
   "metadata": {},
   "source": [
    "`get_field` extracts a value from either a dict-like object (using `[k]`) or a dataclass/object (using `getattr`). This lets us handle both `Record` and dataclass results uniformly:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ef66a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_field(r, k):\n",
    "    return r[k] if isinstance(r, Mapping) else getattr(r, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f24790e",
   "metadata": {},
   "source": [
    "`pks_and_rows_where` wraps `rows_where` but returns `(pk, row)` tuples — useful when you need to know which primary key each row has without inspecting the row itself."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6ca8d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def pks_and_rows_where(self:Table, **kwargs):\n",
    "    \"Like rows_where but returns (pk, row) tuples\"\n",
    "    rows = await self.rows_where(**kwargs)\n",
    "    pk = self.pks[0] if self.pks else None\n",
    "    return [(get_field(r, pk) if pk else None, r) for r in rows]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d53966b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, Artist(artist_id=1, name='AC/DC')),\n",
       " (2, Artist(artist_id=2, name='Accept')),\n",
       " (3, Artist(artist_id=3, name='Aerosmith'))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await artist.pks_and_rows_where(limit=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ed5a7f8",
   "metadata": {},
   "source": [
    "`__call__` makes tables callable, providing a convenient shorthand for queries. `await artist(limit=3)` is equivalent to `await artist.rows_where(limit=3)`. The `with_pk` parameter switches to returning `(pk, row)` tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0774d383",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def __call__(self:Table, where=None, where_args=None, order_by=None, limit=None, offset=None, select='*', with_pk=False,\n",
    "    as_cls=True, debug=False):\n",
    "    \"Query table rows\"\n",
    "    f = self.pks_and_rows_where if with_pk else self.rows_where\n",
    "    return await f(where=where, where_args=where_args, order_by=order_by, limit=limit, offset=offset, select=select,\n",
    "        as_cls=as_cls, debug=debug)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f360b315",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Artist(artist_id=1, name='AC/DC'),\n",
       " Artist(artist_id=2, name='Accept'),\n",
       " Artist(artist_id=3, name='Aerosmith')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await artist(limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a28cacc3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, Artist(artist_id=1, name='AC/DC')),\n",
       " (2, Artist(artist_id=2, name='Accept')),\n",
       " (3, Artist(artist_id=3, name='Aerosmith'))]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await artist(limit=3, with_pk=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d59e239",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Album(album_id=1, title='For Those About To Rock We Salute You', artist_id=1),\n",
       " Album(album_id=4, title='Let There Be Rock', artist_id=1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album.xtra(artist_id=1)\n",
    "await album(limit=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092de809",
   "metadata": {},
   "source": [
    "`selectone` returns exactly one row matching the query, raising `NotFoundError` if none found or `ValueError` if multiple found. It passes `limit=2` internally so it can detect the \"not unique\" case without fetching the entire table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e88814",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def selectone(\n",
    "    self:Table,\n",
    "    where:str|None=None,  # SQL where fragment to use, for example `id > ?`\n",
    "    where_args: Iterable|dict|NoneType=None, # Parameters to use with `where`; iterable for `id>?`, or dict for `id>:id`\n",
    "    select:str = \"*\", # Comma-separated list of columns to select\n",
    "    as_cls:bool=True, # Convert returned dict to stored dataclass?\n",
    "    debug:bool=False\n",
    ")->list:\n",
    "    \"Shortcut for `__call__` that returns exactly one item\"\n",
    "    res = await self(where=where, where_args=where_args, select=select, as_cls=as_cls, limit=2, debug=debug)\n",
    "    if len(res)==0: raise NotFoundError\n",
    "    elif len(res) > 1: raise ValueError(f\"Not unique: {len(res)} results\")\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060ff595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT * FROM \"artist\" WHERE Name=$1 LIMIT 2\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Artist(artist_id=1, name='AC/DC')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await artist.selectone('Name=$1', ('AC/DC',), debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2de93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: await artist.selectone('Name like $1', ('%a%',))\n",
    "except ValueError: pass\n",
    "else: raise Exception(\"Failed to get non unique exception\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6911c60e",
   "metadata": {},
   "outputs": [],
   "source": [
    "try: await artist.selectone('Name=$1', ('i do not exist',))\n",
    "except NotFoundError: pass\n",
    "else: raise Exception(\"Failed to get NotFoundError\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ecdb071",
   "metadata": {},
   "source": [
    "`db.item` is for scalar queries — it returns a single field from a single row. Useful for things like `SELECT count(*)` or `SELECT max(price)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215c7630",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def item(self:Database, sql, args=None):\n",
    "    \"Execute sql and return a single field from a single row\"\n",
    "    res = await self.fetch(sql, *(args or []))\n",
    "    if len(res)==0: raise NotFoundError\n",
    "    elif len(res) > 1: raise ValueError(f\"Not unique: {len(res)} results\")\n",
    "    row = res[0]\n",
    "    if len(row) > 1: raise ValueError(f\"Too many fields: {len(row)} fields\")\n",
    "    return row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "676c3a7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await db.item('select artist_id from artist where name=$1', ('AC/DC',))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5ca4573",
   "metadata": {},
   "source": [
    "## create_mod"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbee9c06",
   "metadata": {},
   "source": [
    "`create_mod` generates a Python module file containing dataclass definitions for all tables in the database. This lets you import type-checked dataclasses directly rather than regenerating them each time. The generated file includes proper imports and uses `UNSET` defaults for flexible instantiation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0261da8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def create_mod(db, mod_fn, with_views=False, store=True, suf=''):\n",
    "    \"Create module for dataclasses for `db`\"\n",
    "    mod_fn = str(mod_fn)\n",
    "    if not mod_fn.endswith('.py'): mod_fn+='.py'\n",
    "    dcs = all_dcs(db, with_views, store=store, suf=suf)\n",
    "    strlist = ', '.join([f'\"{o.__name__}\"' for o in dcs])\n",
    "    with open(mod_fn, 'w') as f:\n",
    "        print(f'__all__ = [{strlist}]', file=f)\n",
    "        print('from dataclasses import dataclass', file=f)\n",
    "        print('import datetime,decimal', file=f)\n",
    "        print('from uuid import UUID', file=f)\n",
    "        print('from fastcore.utils import UNSET', file=f)\n",
    "        for o in dcs: print(dataclass_src(o), file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4ce5d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_mod(db, 'db_dc')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8073e838",
   "metadata": {},
   "source": [
    "`link_dcs` reconnects a database's tables to dataclasses from a previously generated module. This is useful when you've imported dataclasses from a file created by `create_mod` and want the ORM to use them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2002bcaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def link_dcs(self:Database, mod):\n",
    "    \"Set the internal dataclass type links for tables using `mod` (created via `create_mod`)\"\n",
    "    for o in mod.__all__: self.t[o.lower()].cls = getattr(mod, o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053ee2df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Track(track_id=1, name='For Those About To Rock (We Salute You)', album_id=1, media_type_id=1, genre_id=1, composer='Angus Young, Malcolm Young, Brian Johnson', milliseconds=343719, bytes=11170334, unit_price=Decimal('0.99'))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "from db_dc import *\n",
    "await dt.track[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8565260",
   "metadata": {},
   "source": [
    "`set_classes` is a convenience method that links all table dataclasses from a namespace (typically `globals()`). It expects dataclass names to be title-cased versions of table names (e.g., `Artist` for table `artist`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de706b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def set_classes(self:Database, glb):\n",
    "    \"Add set all table dataclasses using types in namespace `glb`\"\n",
    "    for tbl in self.t: tbl.cls = glb[tbl.name.title()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080f615",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "artist, album, employee, customer, invoice, invoice_line, track, playlist, playlist_track, genre, media_type, cat, dog, toy"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db.t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6b83699",
   "metadata": {},
   "source": [
    "`get_tables` injects table objects into a namespace with pluralized names — so `db.t.album` becomes available as `albums`. Combined with `set_classes`, this gives you a clean API: `await albums(limit=3)` returns a list of `Album` dataclass instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25449f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "def get_tables(self:Database, glb):\n",
    "    \"Add objects for all table objects to namespace `glb`\"\n",
    "    for tbl in self.t: glb[tbl.name.lower()+'s'] = tbl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab4c3f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Album(album_id=1, title='For Those About To Rock We Salute You', artist_id=1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| eval: false\n",
    "db.set_classes(globals())\n",
    "db.get_tables(globals())\n",
    "\n",
    "await albums(limit=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4722af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Employee(employee_id=1, last_name='Adams', first_name='Andrew', title='General Manager', reports_to=None, birth_date=datetime.datetime(1962, 2, 18, 0, 0), hire_date=datetime.datetime(2002, 8, 14, 0, 0), address='11120 Jasper Ave NW', city='Edmonton', state='AB', country='Canada', postal_code='T5K 2N1', phone='+1 (780) 428-9482', fax='+1 (780) 428-3457', email='andrew@chinookcorp.com')]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await employees(limit=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "818b4343",
   "metadata": {},
   "source": [
    "## insert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b6355b",
   "metadata": {},
   "source": [
    "To support both dataclasses and dicts as input, and to handle `Enum` values properly, we need these imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82a57623",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from dataclasses import asdict\n",
    "from enum import Enum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7193188",
   "metadata": {},
   "source": [
    "`_process_row` converts a dataclass (or dict) to a plain dict, filtering out `UNSET` values and extracting `.value` from Enum fields. This lets you pass partially-filled dataclasses to `insert`/`update`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b405dc99",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _process_row(row, kwargs):\n",
    "    if row is None: d = {}\n",
    "    elif not is_dataclass(row): d = dict(row) if hasattr(row, 'items') else {}\n",
    "    else: d = {k:(v.value if isinstance(v, Enum) else v) for k,v in asdict(row).items() if v is not UNSET}\n",
    "    return d|kwargs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519986ec",
   "metadata": {},
   "source": [
    "`insert` adds a row to the table. It accepts either a dataclass/dict as `record`, keyword arguments, or both (kwargs override record fields). PostgreSQL's `RETURNING *` clause lets us get the inserted row back in one query — including any auto-generated values like `SERIAL` primary keys. The `xtra` constraints are automatically merged in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "343a8cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _prep_row(record, kwargs):\n",
    "    row = _process_row(record, kwargs)\n",
    "    if not row: return None*3\n",
    "    cols = ', '.join(f'\"{k}\"' for k in row)\n",
    "    vals = ', '.join(f'${i+1}' for i in range(len(row)))\n",
    "    return row, cols, vals\n",
    "\n",
    "@patch\n",
    "async def _exec_returning(self:Table, sql, *args):\n",
    "    res = await self.db.fetch(sql, *args)\n",
    "    return self.cls(**res[0]) if hasattr(self, 'cls') else res[0]\n",
    "\n",
    "@patch\n",
    "async def insert(self:Table, record=None, **kwargs):\n",
    "    \"Insert a row and return it\"\n",
    "    row, cols, vals = _prep_row(record, {**kwargs, **self.xtra_id})\n",
    "    if not row: return None\n",
    "    sql = f'INSERT INTO {self} ({cols}) VALUES ({vals}) RETURNING *'\n",
    "    return await self._exec_returning(sql, *row.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b18f5ad",
   "metadata": {},
   "source": [
    "For DDL statements like `CREATE TABLE`, use `execute` rather than `fetch`/`q`. DDL statements don't return rows — they return a status string like `'CREATE TABLE'`. PostgreSQL uses `SERIAL` for auto-incrementing integers (instead of SQLite's `INTEGER PRIMARY KEY`) and `REAL` instead of `FLOAT`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e56b97ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'CREATE TABLE'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await db.execute('''\n",
    "DROP TABLE IF EXISTS cat;\n",
    "CREATE TABLE cat (\n",
    "    id SERIAL PRIMARY KEY,\n",
    "    name TEXT,\n",
    "    weight REAL,\n",
    "    uid INTEGER\n",
    ")''')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d325a8",
   "metadata": {},
   "source": [
    "`_retr_tbl` is a helper that refreshes the database metadata and returns the table object for a given name. This ensures you're working with up-to-date schema information after creating or modifying tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a782068",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def _retr_tbl(self:Database, name):\n",
    "    await self.refresh()\n",
    "    return self.t[name]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98977fa7",
   "metadata": {},
   "source": [
    "`table2glb` is a convenience method that refreshes metadata, creates the dataclass, and injects both the table object (pluralized name) and the dataclass into a namespace. This is handy after creating a new table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e5e35ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import inspect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c78b87",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def table2glb(self:Database, name, glb=None):\n",
    "    \"Get table by name, refreshing metadata and creating dataclass, adding to glb\"\n",
    "    if glb is None: glb = inspect.currentframe().f_back.f_globals\n",
    "    tbl = await self._retr_tbl(name)\n",
    "    cls = tbl.dataclass()\n",
    "    glb[name],glb[cls.__name__] = tbl,cls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f5b218",
   "metadata": {},
   "outputs": [],
   "source": [
    "await db.table2glb('cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec63e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table \"cat\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d423ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat(id=1, name='meow', weight=6.0, uid=2)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = await cat.insert(name='meow', weight=6, uid=2)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "302bb461",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Cat(id=1, name='meow', weight=6.0, uid=2)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9429f09c",
   "metadata": {},
   "source": [
    "With `xtra` set, `insert` automatically includes those constraints. Here we set `uid=1`, so the inserted cat gets that value even though we didn't pass it explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d37142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat(id=2, name='purr', weight=4.0, uid=1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.xtra(uid=1)\n",
    "c2 = await cat.insert(name='purr', weight=4)\n",
    "c2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914655a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Cat(id=2, name='purr', weight=4.0, uid=1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e901126",
   "metadata": {},
   "source": [
    "Calling `xtra()` with no arguments clears the filter by setting `xtra_id = {}`. Now queries return all rows again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b3f72f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table \"cat\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.xtra()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aad2f74",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Cat(id=1, name='meow', weight=6.0, uid=2),\n",
       " Cat(id=2, name='purr', weight=4.0, uid=1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat()  # Should now return all cats, not just uid=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eabf7d5",
   "metadata": {},
   "source": [
    "## update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcee68af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat(id=1, name='moo', weight=6.0, uid=1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.name = \"moo\"\n",
    "c.uid = 1\n",
    "c"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10ea2bc0",
   "metadata": {},
   "source": [
    "`_pk_where` builds a WHERE clause for primary key matching, using PostgreSQL's `$1, $2` placeholders with an offset to account for preceding parameters in the query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b261543",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def _pk_where(pks, offset=0):\n",
    "    return ' AND '.join(f'\"{pk}\"=${i+offset+1}' for i,pk in enumerate(pks))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce81faca",
   "metadata": {},
   "source": [
    "`update` modifies an existing row by primary key. It builds an `UPDATE ... SET ... WHERE pk = $n RETURNING *` statement. Like `insert`, it respects `xtra` constraints — if you try to update a row that doesn't match the `xtra` filter, you'll get `NotFoundError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f2edca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def update(self:Table, record=None, pk_values=None, **kwargs):\n",
    "    \"Update a row and return it\"\n",
    "    row = _process_row(record, kwargs)\n",
    "    if not row: return None\n",
    "    if pk_values is None: pk_values = [row[o] for o in self.pks]\n",
    "    sets = ', '.join(f'\"{k}\"=${i+1}' for i,k in enumerate(row))\n",
    "    xwhere = _pk_where(self.pks, len(row))\n",
    "    pk_where, args = _add_xtra(self, xwhere, pk_values, len(row))\n",
    "    sql = f'UPDATE {self} SET {sets} WHERE {pk_where} RETURNING *'\n",
    "    res = await self.db.fetch(sql, *row.values(), *args)\n",
    "    if not res: raise NotFoundError(f\"{self.name}[{pk_values}]\")\n",
    "    return self.cls(**res[0]) if hasattr(self, 'cls') else res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba56f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat(id=1, name='moo', weight=6.0, uid=1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat.update(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5b2543",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Cat(id=2, name='purr', weight=4.0, uid=1),\n",
       " Cat(id=1, name='moo', weight=6.0, uid=1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3202757",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly blocked: cat[[1]]\n"
     ]
    }
   ],
   "source": [
    "cat.xtra(uid=2)\n",
    "c.uid = 2\n",
    "try: await cat.update(c)  # Should fail - c has id=1 which has uid=1, not uid=2\n",
    "except NotFoundError as e: print('Correctly blocked:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faf46a30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table \"cat\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.xtra()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "012bc0fa",
   "metadata": {},
   "source": [
    "## delete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a77c05",
   "metadata": {},
   "source": [
    "`delete` removes a row by primary key, returning the deleted row (using `RETURNING *`). Like the other methods, it respects `xtra` constraints — attempting to delete a row that doesn't match the filter raises `NotFoundError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9968e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def delete(self:Table, pk_values):\n",
    "    \"Delete row by primary key, returning the deleted row\"\n",
    "    pk_where, args = _add_xtra(self, _pk_where(self.pks), listify(pk_values))\n",
    "    sql = f'DELETE FROM {self} WHERE {pk_where} RETURNING *'\n",
    "    res = await self.db.fetch(sql, *args)\n",
    "    if not res: raise NotFoundError(f\"{self.name}[{pk_values}]\")\n",
    "    return self.cls(**res[0]) if hasattr(self, 'cls') else res[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b894b993",
   "metadata": {},
   "source": [
    "Let's verify delete works — first check what cats we have:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8acfcde",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Cat(id=2, name='purr', weight=4.0, uid=1),\n",
       " Cat(id=1, name='moo', weight=6.0, uid=1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30b1a4d",
   "metadata": {},
   "source": [
    "Delete returns the deleted row, so you can see exactly what was removed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dde9a9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat(id=1, name='moo', weight=6.0, uid=1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat.delete(c.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e7201a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Cat(id=2, name='purr', weight=4.0, uid=1)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbcf85ac",
   "metadata": {},
   "source": [
    "The `xtra` filter also applies to deletes. If you try to delete a row that doesn't match the constraint, you get `NotFoundError`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f576eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly blocked: cat[2]\n"
     ]
    }
   ],
   "source": [
    "cat.xtra(uid=99)\n",
    "try: await cat.delete(2)  # Should fail - cat 2 has uid=1, not uid=99\n",
    "except NotFoundError as e: print('Correctly blocked:', e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fa5ea2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table \"cat\""
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat.xtra()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a7b47f",
   "metadata": {},
   "source": [
    "`delete_where` is the bulk version of `delete` — it removes all rows matching a WHERE clause (or all rows if none given), returning the deleted rows as a list. Like `delete`, it respects `xtra` constraints and uses `RETURNING *` to give back what was removed. This is useful for cleanup operations like removing all rows above a threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc57f94",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def delete_where(self:Table, where=None, where_args=None):\n",
    "    where, args = _add_xtra(self, where, where_args or [])\n",
    "    sql = f'DELETE FROM {self}' + (f' WHERE {where}' if where else '') + ' RETURNING *'\n",
    "    res = await self.db.fetch(sql, *args)\n",
    "    if hasattr(self, 'cls'): res = [self.cls(**r) for r in res]\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "322fa8c8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Cat(id=4, name='Skitter', weight=2.0, uid=None)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat.insert(name='Cat McCat Face', weight=9)\n",
    "await cat.insert(name='Skitter', weight=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6958ba7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Cat(id=2, name='purr', weight=4.0, uid=1),\n",
       " Cat(id=3, name='Cat McCat Face', weight=9.0, uid=None)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat.delete_where('weight > $1', [3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0441bc4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Cat(id=4, name='Skitter', weight=2.0, uid=None)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await cat()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000dd560",
   "metadata": {},
   "source": [
    "## Create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fa3ca74",
   "metadata": {},
   "source": [
    "To create tables from Python classes, we need a reverse mapping from Python types to PostgreSQL types. We generate it from `pg_to_py` and override some entries for cleaner defaults (e.g., `TEXT` instead of `character varying`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d45f513e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "py_to_pg = {v: k for k, v in pg_to_py.items() if v not in (list, tuple, Range)}\n",
    "# Override some for cleaner defaults\n",
    "py_to_pg.update({int: 'INTEGER', str: 'TEXT', float: 'REAL', bool: 'BOOLEAN'})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6be2875d",
   "metadata": {},
   "source": [
    "`col_def` builds a column definition for `CREATE TABLE`. If the column is the primary key and has type `int`, it becomes `SERIAL PRIMARY KEY` (PostgreSQL's auto-incrementing integer). Otherwise it maps the Python type to PostgreSQL and adds `NOT NULL` if specified."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6d1a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def col_def(name, typ, pk, not_null):\n",
    "    \"Build column definition SQL for CREATE TABLE\"\n",
    "    pg_typ = py_to_pg.get(typ, 'TEXT')\n",
    "    if name == pk and typ == int: pg_typ = 'SERIAL'\n",
    "    parts = [f'\"{name}\"', pg_typ]\n",
    "    if name == pk: parts.append('PRIMARY KEY')\n",
    "    elif not_null and name in not_null: parts.append('NOT NULL')\n",
    "    return ' '.join(parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c32920f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"id\" SERIAL PRIMARY KEY'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_def('id', int, 'id', None)  # 'id' is pk and int -> SERIAL PRIMARY KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "505042da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"name\" TEXT NOT NULL'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_def('name', str, 'id', {'name'})  # not pk, in not_null -> TEXT NOT NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8529c9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"age\" INTEGER'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_def('age', int, 'id', None)  # not pk -> INTEGER"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b37fabdb",
   "metadata": {},
   "source": [
    "`db.create` creates a table from a Python class (or dataclass). It extracts field names and types, builds column definitions, and executes the `CREATE TABLE` statement. The `replace=True` option drops any existing table first (with `CASCADE` to handle dependencies)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c17673d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def create(self:Database, cls=None, name=None, pk='id', foreign_keys=None, defaults=None, \n",
    "                 column_order=None, not_null=None, if_not_exists=False, replace=False):\n",
    "    \"Create table from `cls`\"\n",
    "    flexiclass(cls)\n",
    "    if name is None: name = camel2snake(cls.__name__)\n",
    "    typs = {o.name: o.type for o in fields(cls)}\n",
    "    if column_order: typs = {k: typs[k] for k in column_order if k in typs}\n",
    "    \n",
    "    cols = [col_def(k, v, pk, not_null) for k, v in typs.items()]\n",
    "    if defaults:\n",
    "        for i, (k, v) in enumerate(typs.items()):\n",
    "            if k in defaults: cols[i] += f' DEFAULT {defaults[k]!r}'\n",
    "    if foreign_keys:\n",
    "        for col, (ref_tbl, ref_col) in foreign_keys.items():\n",
    "            cols.append(f'FOREIGN KEY (\"{col}\") REFERENCES \"{ref_tbl}\" (\"{ref_col}\")')\n",
    "    \n",
    "    col_sql = ', '.join(cols)\n",
    "    exists = 'IF NOT EXISTS ' if if_not_exists else ''\n",
    "    if replace: await self.execute(f'DROP TABLE IF EXISTS \"{name}\" CASCADE')\n",
    "    await self.execute(f'CREATE TABLE {exists}\"{name}\" ( {col_sql} )')\n",
    "    tbl = await self._retr_tbl(name)\n",
    "    tbl.cls = cls\n",
    "    return tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92723717",
   "metadata": {},
   "source": [
    "`drop` removes a table from the database. The `cascade=True` option also drops any dependent objects (like foreign key references from other tables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de113b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def drop(self:Table, cascade=False):\n",
    "    \"Drop this table\"\n",
    "    casc = ' CASCADE' if cascade else ''\n",
    "    await self.db.execute(f'DROP TABLE IF EXISTS {self}{casc}')\n",
    "    await self.db.refresh()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2db9b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "await db.t.dog.drop(cascade=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c3ecc4",
   "metadata": {},
   "source": [
    "Now let's test `create` with a simple `Dog` class:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4580dd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'integer', 'name': 'text', 'age': 'integer'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Dog: id:int; name:str; age:int\n",
    "\n",
    "dogs = await db.create(Dog, replace=True)\n",
    "dogs.cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cc8c829",
   "metadata": {},
   "source": [
    "The auto-generated `SERIAL` primary key handles auto-increment automatically:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "528fc71a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dog(id=1, name='Rex', age=5)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = await dogs.insert(name='Rex', age=5)\n",
    "d"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a36c437",
   "metadata": {},
   "source": [
    "Foreign keys are specified as a dict mapping column names to `(table, column)` tuples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "331598d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'integer', 'name': 'text', 'dog_id': 'integer'}"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Toy: id:int; name:str; dog_id:int\n",
    "\n",
    "toys = await db.create(Toy, replace=True, foreign_keys={'dog_id': ('dog', 'id')})\n",
    "toys.cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3db9ec9",
   "metadata": {},
   "source": [
    "The foreign key constraint is enforced by PostgreSQL — inserting a toy with an invalid `dog_id` would raise an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8233069a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Toy(id=1, name='Ball', dog_id=1)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = await toys.insert(name='Ball', dog_id=d.id)\n",
    "t"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e428975e",
   "metadata": {},
   "source": [
    "## Upsert"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df312453",
   "metadata": {},
   "source": [
    "`upsert` performs an \"insert or update\" operation using PostgreSQL's `ON CONFLICT ... DO UPDATE` clause. If a row with the same primary key exists, it updates it; otherwise it inserts a new row. Like `insert`, it uses `_prep_row` for row processing and `_exec_returning` for result handling, and respects `xtra` constraints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b5bd8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "@patch\n",
    "async def upsert(self:Table, record=None, **kwargs):\n",
    "    \"Insert or update a row and return it\"\n",
    "    row, cols, vals = _prep_row(record, {**kwargs, **self.xtra_id})\n",
    "    if not row: return None\n",
    "    pk = self.pks[0]\n",
    "    updates = ', '.join(f'\"{k}\"=EXCLUDED.\"{k}\"' for k in row if k != pk)\n",
    "    sql = f'INSERT INTO {self} ({cols}) VALUES ({vals}) ON CONFLICT (\"{pk}\") DO UPDATE SET {updates} RETURNING *'\n",
    "    return await self._exec_returning(sql, *row.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "230517f1",
   "metadata": {},
   "source": [
    "Let's test upsert — first check current state:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f98f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dog(id=1, name='Rex', age=5)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await dogs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f791c630",
   "metadata": {},
   "source": [
    "Updating an existing row — change Rex's age from 5 to 6:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b806be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dog(id=1, name='Rex', age=6)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d.age = 6\n",
    "await dogs.upsert(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2c837ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dog(id=1, name='Rex', age=6)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await dogs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19d4bc78",
   "metadata": {},
   "source": [
    "Inserting a new row — upsert without an existing id creates a new record:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fd4cd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dog(id=2, name='Spot', age=3)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await dogs.upsert(name='Spot', age=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d28bffd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Dog(id=1, name='Rex', age=6), Dog(id=2, name='Spot', age=3)]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "await dogs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746b7f8c",
   "metadata": {},
   "source": [
    "With `xtra` set, upsert merges those constraints into the row:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d84cdd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dog(id=1, name='Rexy', age=6)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dogs.xtra(age=6)\n",
    "d.name = 'Rexy'\n",
    "await dogs.upsert(d)  # Should set age=6 from xtra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff086f5e",
   "metadata": {},
   "source": [
    "## Connection pool"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df83d611",
   "metadata": {},
   "source": [
    "For production use, you'll want a connection pool instead of a single connection. `asyncpg.Pool` has the same query methods (`fetch`, `execute`, etc.) as a connection, so our `Database` wrapper works with both. The key difference is that JSON codecs must be registered via the `init` callback (which runs on each new connection in the pool)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be00990",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "async def create_pool(*args, **kwargs):\n",
    "    kwargs.setdefault('record_class', FRecord)\n",
    "    kwargs.setdefault('init', setup_json)\n",
    "    pool = await asyncpg.create_pool(*args, **kwargs)\n",
    "    res = Database(pool, refresh=False)\n",
    "    await res.refresh()\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5611a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "await db.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d61ce4",
   "metadata": {},
   "source": [
    "Let's test that the pool works the same as a single connection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c5353d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<FRecord artist_id=1 name='AC/DC'>,\n",
       " <FRecord artist_id=2 name='Accept'>,\n",
       " <FRecord artist_id=3 name='Aerosmith'>]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = await create_pool(user=user, database='chinook', host='127.0.0.1')\n",
    "await db.t.artist(limit=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49fc19b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'postgresql://natedawg@127.0.0.1:5432/chinook'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(db)"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
