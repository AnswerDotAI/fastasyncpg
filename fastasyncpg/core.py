# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto #0
__all__ = ['pg_to_py', 'py_to_pg', 'Results', 'FRecord', 'table_names', 'view_names', 'columns_info', 'pk_cols', 'Database',
           'Table', 'get_typ', 'setup_json', 'connect', 'all_dcs', 'NotFoundError', 'get_field', 'create_mod',
           'col_def', 'create_pool']

# %% ../nbs/00_core.ipynb #222d751e
from fastcore.utils import *
import asyncpg
from asyncpg import connection,protocol

# %% ../nbs/00_core.ipynb #cdb9cd9e
class Results(list):
    def _repr_html_(self):
        if not self: return ""
        ks = list(self[0].keys())
        ths = "".join(f"<th>{k}</th>" for k in ks)
        trs = "".join(f"<tr>{''.join(f'<td>{v}</td>' for v in r.values())}</tr>" for r in self)
        return f'<table class="prose"><thead><tr>{ths}</tr></thead><tbody>{trs}</tbody></table>'

# %% ../nbs/00_core.ipynb #25f59343
from asyncpg.protocol.record import Record

# %% ../nbs/00_core.ipynb #e9a012cd
class FRecord(Record):
    def __getattr__(self, k):
        if k.startswith('_'): raise AttributeError(k)
        return self[k]

    def _repr_html_(self):
        rows = "".join(f"<tr><td>{k}</td><td>{v}</td></tr>" for k,v in self.items())
        return f'<table class="prose"><thead><tr><th>Field</th><th>Value</th></tr></thead><tbody>{rows}</tbody></table>'

# %% ../nbs/00_core.ipynb #7c604795
async def table_names(conn, schema='public'):
    "List of table names in `schema`"
    res = await conn.fetch("""
        SELECT c.relname FROM pg_class c
        JOIN pg_namespace n ON n.oid = c.relnamespace
        WHERE n.nspname = $1 AND c.relkind = 'r' AND NOT c.relname LIKE 'pg_%'""", schema)
    return [r['relname'] for r in res]

async def view_names(conn, schema='public'):
    "List of view names in `schema`"
    res = await conn.fetch("""
        SELECT c.relname FROM pg_class c
        JOIN pg_namespace n ON n.oid = c.relnamespace
        WHERE n.nspname = $1 AND c.relkind = 'v'""", schema)
    return [r['relname'] for r in res]

# %% ../nbs/00_core.ipynb #29cf6d50
async def columns_info(conn, table, schema='public'):
    "Dict mapping column names to data types for `table`"
    res = await conn.fetch("""
        SELECT a.attname, format_type(a.atttypid, a.atttypmod) as data_type
        FROM pg_attribute a
        JOIN pg_class c ON c.oid = a.attrelid
        JOIN pg_namespace n ON n.oid = c.relnamespace
        WHERE n.nspname = $1 AND c.relname = $2 AND a.attnum > 0 AND NOT a.attisdropped
        ORDER BY a.attnum""", schema, table)
    return {r['attname']: r['data_type'] for r in res}

# %% ../nbs/00_core.ipynb #f504a98b
async def pk_cols(conn, table):
    "Get primary key column(s) for `table`"
    res = await conn.fetch("""
        SELECT a.attname FROM pg_index i
        JOIN pg_attribute a ON a.attrelid = i.indrelid AND a.attnum = ANY(i.indkey)
        WHERE i.indrelid = $1::regclass AND i.indisprimary""", table)
    return [r['attname'] for r in res]

# %% ../nbs/00_core.ipynb #350e6168
class Database:
    def __init__(self, conn, refresh=True):
        self.conn = conn
        self._tnames,self._vnames = [],[]
        self._tables = {}
        if refresh: asyncio.create_task(self.refresh())

    @property
    def t(self):
        if not hasattr(self, '_t'): self._t = _TablesGetter(self)
        return self._t

    def __getattr__(self, k): return getattr(self.conn, k)

    def table(self, name):
        if name not in self._tables: self._tables[name] = Table(self, name)
        return self._tables[name]

    async def refresh(self):
        "Refresh all metadata"
        self._tnames,self._vnames = await table_names(self),await view_names(self)
        self._cols = {o: (await columns_info(self, o)) for o in self._tnames+self._vnames}
        self._pks = {o: (await pk_cols(self, o)) for o in self._tnames}

# %% ../nbs/00_core.ipynb #ae461a23
class Table:
    def __init__(self, db, name):
        store_attr()
        self.xtra_id = {}

    @property
    def cols(self): return self.db._cols.get(self.name, {})
    def __repr__(self): return f'Table "{self.name}"'
    def __str__(self): return f'"{self.name}"'

    def xtra(self, **kwargs):
        "Set extra constraints for queries/inserts"
        self.xtra_id = kwargs
        return self

    @property
    def pks(self): return self.db._pks.get(self.name, [])

# %% ../nbs/00_core.ipynb #c0374b56
class _Getter:
    def __init__(self, db, attr): self.db,self.attr = db,attr

    def __repr__(self): return ", ".join(getattr(self.db, self.attr))
    def __dir__(self): return getattr(self.db, self.attr)
    def __iter__(self): return iter(self[dir(self)])
    def __contains__(self, s): return (s if isinstance(s,str) else s.name) in dir(self)
    def __getitem__(self, idxs):
        if isinstance(idxs,str): return self.db.table(idxs)
        return [self.db.table(o) for o in idxs]
    def __getattr__(self, k):
        if k.startswith('_'): raise AttributeError
        return self.db.table(k)

class _TablesGetter(_Getter):
    def __init__(self, db): super().__init__(db,'_tnames')

# %% ../nbs/00_core.ipynb #699ea455
class _Col:
    def __init__(self, t, c): self.t,self.c = t,c
    def __str__(self):  return f'"{self.t}"."{self.c}"'
    def __repr__(self):  return self.c
    def __iter__(self): return iter(self.c)

class _ColsGetter:
    def __init__(self, tbl): self.tbl = tbl
    def __dir__(self): return list(self.tbl.cols)
    def __repr__(self): return ", ".join(dir(self))
    def __call__(self): return [_Col(self.tbl.name,o.name) for o in self.tbl.columns]
    def __contains__(self, s): return (s if isinstance(s,str) else s.c) in self.tbl.cols
    def __getattr__(self, k):
        if k[0]=='_': raise AttributeError
        return _Col(self.tbl.name, k)

@patch(as_prop=True)
def c(self:Table): return _ColsGetter(self)

# %% ../nbs/00_core.ipynb #891dcd10
@patch
async def q(self:Database, sql, *args): return Results(await self.fetch(sql, *args))

# %% ../nbs/00_core.ipynb #0fc7310b
from datetime import datetime, date, time, timedelta
from decimal import Decimal
from uuid import UUID
from ipaddress import IPv4Network, IPv6Network, IPv4Interface, IPv6Interface, IPv4Address, IPv6Address
from asyncpg.types import Range, BitString, Box, Circle, Line, LineSegment, Path, Point, Polygon

# %% ../nbs/00_core.ipynb #a559e812
def get_typ(pg_type):
    "Get Python type for PostgreSQL type string"
    return pg_to_py[pg_type.split('(')[0].strip()]

# %% ../nbs/00_core.ipynb #a17706fc
pg_to_py = {
    'smallint': int, 'integer': int, 'bigint': int,
    'real': float, 'float': float, 'double precision': float,
    'numeric': Decimal, 'decimal': Decimal,
    
    'char': str, 'character': str, 'name': str, 'varchar': str, 'character varying': str, 'text': str, 'xml': str,
    'bytea': bytes,
    'boolean': bool, 'bool': bool,
    
    'date': date,
    'time': time, 'time without time zone': time, 'time with time zone': time,
    'timestamp': datetime, 'timestamp without time zone': datetime, 'timestamp with time zone': datetime,
    'interval': timedelta,
    
    'uuid': UUID,
    'json': dict, 'jsonb': dict,
    'money': str,
    'macaddr': str,
    
    'cidr': IPv4Network, 'inet': IPv4Interface,
    
    'bit': BitString, 'varbit': BitString,
    'box': Box, 'circle': Circle, 'line': Line, 'lseg': LineSegment,
    'path': Path, 'point': Point, 'polygon': Polygon,
    
    'anyarray': list, 'ARRAY': list,
    'anyrange': Range,
    'record': tuple, 'tid': tuple,
}

# %% ../nbs/00_core.ipynb #a5c571d1
import json

# %% ../nbs/00_core.ipynb #9282bec2
async def setup_json(conn):
    await conn.set_type_codec('json', encoder=json.dumps, decoder=json.loads, schema='pg_catalog')
    await conn.set_type_codec('jsonb', encoder=json.dumps, decoder=json.loads, schema='pg_catalog')

# %% ../nbs/00_core.ipynb #e95ad25a
async def connect(*args, **kwargs):
    kwargs.setdefault('record_class', FRecord)
    conn = await asyncpg.connect(*args, **kwargs)
    await setup_json(conn)
    res = Database(conn, refresh=False)
    await res.refresh()
    return res

# %% ../nbs/00_core.ipynb #341b22b5
from dataclasses import dataclass, field, make_dataclass, fields, Field, is_dataclass, MISSING

# %% ../nbs/00_core.ipynb #8402e3b8
def _get_flds(tbl): 
    return [(k, get_typ(v)|None, field(default=UNSET))
            for k,v in tbl.cols.items()]

def _dataclass(self:Table, store=True, suf='')->type:
    "Create a `dataclass` with the types and defaults of this table"
    res = make_dataclass(self.name.title()+suf, _get_flds(self))
    flexiclass(res)
    if store: self.cls = res
    return res

Table.dataclass = _dataclass

# %% ../nbs/00_core.ipynb #cf91a162
def all_dcs(db, with_views=False, store=True, suf=''):
    "dataclasses for all objects in `db`"
    return [o.dataclass(store=store, suf=suf) for o in list(db.t) + (db.views if with_views else [])]

# %% ../nbs/00_core.ipynb #b37f834d
def _add_xtra(tbl, where, args, offset=0):
    if not tbl.xtra_id: return where, args
    args = list(args)
    xw = ' AND '.join(f'"{k}"=${len(args)+offset+i+1}' for i,k in enumerate(tbl.xtra_id))
    where = f'({where}) AND {xw}' if where else xw
    args.extend(tbl.xtra_id.values())
    return where, args

# %% ../nbs/00_core.ipynb #de5874df
class NotFoundError(Exception): pass

@patch
async def __getitem__(self:Table, pk):
    "Get row by primary key, raising NotFoundError if missing"
    if not self.pks: raise ValueError(f"No primary key for {self.name}")
    where, args = _add_xtra(self, f'"{self.pks[0]}" = $1', [pk])
    res = await self.db.fetch(f'SELECT * FROM {self} WHERE {where}', *args)
    if not res: raise NotFoundError(f"{self.name}[{pk}]")
    return self.cls(**res[0]) if hasattr(self, 'cls') else res[0]

# %% ../nbs/00_core.ipynb #76a582ae
@patch
async def get(self:Table, pk):
    "Get row by primary key, or None if missing"
    try: return await self[pk]
    except NotFoundError: return None

# %% ../nbs/00_core.ipynb #fd2d38a2
@patch
async def rows_where(self:Table, where=None, where_args=None, order_by=None, select='*', limit=None, offset=None,
    as_cls=True, debug=False):
    "Iterate over rows matching where clause"
    where, args = _add_xtra(self, where, where_args or [])
    sql = f'SELECT {select} FROM {self}'
    if where: sql += f' WHERE {where}'
    if order_by: sql += f' ORDER BY {order_by}'
    if limit: sql += f' LIMIT {limit}'
    if offset: sql += f' OFFSET {offset}'
    if debug: print(sql)
    res = await self.db.fetch(sql, *args)
    if as_cls and hasattr(self, 'cls'): res = [self.cls(**r) for r in res]
    return res

# %% ../nbs/00_core.ipynb #28682469
from collections.abc import Mapping

# %% ../nbs/00_core.ipynb #8ef66a0f
def get_field(r, k):
    return r[k] if isinstance(r, Mapping) else getattr(r, k)

# %% ../nbs/00_core.ipynb #8e6ca8d9
@patch
async def pks_and_rows_where(self:Table, **kwargs):
    "Like rows_where but returns (pk, row) tuples"
    rows = await self.rows_where(**kwargs)
    pk = self.pks[0] if self.pks else None
    return [(get_field(r, pk) if pk else None, r) for r in rows]

# %% ../nbs/00_core.ipynb #0774d383
@patch
async def __call__(self:Table, where=None, where_args=None, order_by=None, limit=None, offset=None, select='*', with_pk=False,
    as_cls=True, debug=False):
    "Query table rows"
    f = self.pks_and_rows_where if with_pk else self.rows_where
    return await f(where=where, where_args=where_args, order_by=order_by, limit=limit, offset=offset, select=select,
        as_cls=as_cls, debug=debug)

# %% ../nbs/00_core.ipynb #73e88814
@patch
async def selectone(
    self:Table,
    where:str|None=None,  # SQL where fragment to use, for example `id > ?`
    where_args: Iterable|dict|NoneType=None, # Parameters to use with `where`; iterable for `id>?`, or dict for `id>:id`
    select:str = "*", # Comma-separated list of columns to select
    as_cls:bool=True, # Convert returned dict to stored dataclass?
    debug:bool=False
)->list:
    "Shortcut for `__call__` that returns exactly one item"
    res = await self(where=where, where_args=where_args, select=select, as_cls=as_cls, limit=2, debug=debug)
    if len(res)==0: raise NotFoundError
    elif len(res) > 1: raise ValueError(f"Not unique: {len(res)} results")
    return res[0]

# %% ../nbs/00_core.ipynb #215c7630
@patch
async def item(self:Database, sql, args=None):
    "Execute sql and return a single field from a single row"
    res = await self.fetch(sql, *(args or []))
    if len(res)==0: raise NotFoundError
    elif len(res) > 1: raise ValueError(f"Not unique: {len(res)} results")
    row = res[0]
    if len(row) > 1: raise ValueError(f"Too many fields: {len(row)} fields")
    return row[0]

# %% ../nbs/00_core.ipynb #0261da8a
def create_mod(db, mod_fn, with_views=False, store=True, suf=''):
    "Create module for dataclasses for `db`"
    mod_fn = str(mod_fn)
    if not mod_fn.endswith('.py'): mod_fn+='.py'
    dcs = all_dcs(db, with_views, store=store, suf=suf)
    strlist = ', '.join([f'"{o.__name__}"' for o in dcs])
    with open(mod_fn, 'w') as f:
        print(f'__all__ = [{strlist}]', file=f)
        print('from dataclasses import dataclass', file=f)
        print('import datetime,decimal', file=f)
        print('from uuid import UUID', file=f)
        print('from fastcore.utils import UNSET', file=f)
        for o in dcs: print(dataclass_src(o), file=f)

# %% ../nbs/00_core.ipynb #2002bcaf
@patch
def link_dcs(self:Database, mod):
    "Set the internal dataclass type links for tables using `mod` (created via `create_mod`)"
    for o in mod.__all__: self.t[o.lower()].cls = getattr(mod, o)

# %% ../nbs/00_core.ipynb #8de706b8
@patch
def set_classes(self:Database, glb):
    "Add set all table dataclasses using types in namespace `glb`"
    for tbl in self.t: tbl.cls = glb[tbl.name.title()]

# %% ../nbs/00_core.ipynb #a25449f1
@patch
def get_tables(self:Database, glb):
    "Add objects for all table objects to namespace `glb`"
    for tbl in self.t: glb[tbl.name.lower()+'s'] = tbl

# %% ../nbs/00_core.ipynb #82a57623
from dataclasses import asdict
from enum import Enum

# %% ../nbs/00_core.ipynb #b405dc99
def _process_row(row, kwargs):
    if row is None: d = {}
    elif not is_dataclass(row): d = dict(row) if hasattr(row, 'items') else {}
    else: d = {k:(v.value if isinstance(v, Enum) else v) for k,v in asdict(row).items() if v is not UNSET}
    return d|kwargs

# %% ../nbs/00_core.ipynb #343a8cc8
def _prep_row(record, kwargs):
    row = _process_row(record, kwargs)
    if not row: return None*3
    cols = ', '.join(f'"{k}"' for k in row)
    vals = ', '.join(f'${i+1}' for i in range(len(row)))
    return row, cols, vals

@patch
async def _exec_returning(self:Table, sql, *args):
    res = await self.db.fetch(sql, *args)
    return self.cls(**res[0]) if hasattr(self, 'cls') else res[0]

@patch
async def insert(self:Table, record=None, **kwargs):
    "Insert a row and return it"
    row, cols, vals = _prep_row(record, {**kwargs, **self.xtra_id})
    if not row: return None
    sql = f'INSERT INTO {self} ({cols}) VALUES ({vals}) RETURNING *'
    return await self._exec_returning(sql, *row.values())

# %% ../nbs/00_core.ipynb #8a782068
@patch
async def _retr_tbl(self:Database, name):
    await self.refresh()
    return self.t[name]

# %% ../nbs/00_core.ipynb #8e5e35ab
import inspect

# %% ../nbs/00_core.ipynb #e9c78b87
@patch
async def table2glb(self:Database, name, glb=None):
    "Get table by name, refreshing metadata and creating dataclass, adding to glb"
    if glb is None: glb = inspect.currentframe().f_back.f_globals
    tbl = await self._retr_tbl(name)
    cls = tbl.dataclass()
    glb[name],glb[cls.__name__] = tbl,cls

# %% ../nbs/00_core.ipynb #9b261543
def _pk_where(pks, offset=0):
    return ' AND '.join(f'"{pk}"=${i+offset+1}' for i,pk in enumerate(pks))

# %% ../nbs/00_core.ipynb #51f2edca
@patch
async def update(self:Table, record=None, pk_values=None, **kwargs):
    "Update a row and return it"
    row = _process_row(record, kwargs)
    if not row: return None
    if pk_values is None: pk_values = [row[o] for o in self.pks]
    sets = ', '.join(f'"{k}"=${i+1}' for i,k in enumerate(row))
    xwhere = _pk_where(self.pks, len(row))
    pk_where, args = _add_xtra(self, xwhere, pk_values, len(row))
    sql = f'UPDATE {self} SET {sets} WHERE {pk_where} RETURNING *'
    res = await self.db.fetch(sql, *row.values(), *args)
    if not res: raise NotFoundError(f"{self.name}[{pk_values}]")
    return self.cls(**res[0]) if hasattr(self, 'cls') else res[0]

# %% ../nbs/00_core.ipynb #f9968e6f
@patch
async def delete(self:Table, pk_values):
    "Delete row by primary key, returning the deleted row"
    pk_where, args = _add_xtra(self, _pk_where(self.pks), listify(pk_values))
    sql = f'DELETE FROM {self} WHERE {pk_where} RETURNING *'
    res = await self.db.fetch(sql, *args)
    if not res: raise NotFoundError(f"{self.name}[{pk_values}]")
    return self.cls(**res[0]) if hasattr(self, 'cls') else res[0]

# %% ../nbs/00_core.ipynb #d45f513e
py_to_pg = {v: k for k, v in pg_to_py.items() if v not in (list, tuple, Range)}
# Override some for cleaner defaults
py_to_pg.update({int: 'INTEGER', str: 'TEXT', float: 'REAL', bool: 'BOOLEAN'})

# %% ../nbs/00_core.ipynb #21e6d1a5
def col_def(name, typ, pk, not_null):
    "Build column definition SQL for CREATE TABLE"
    pg_typ = py_to_pg.get(typ, 'TEXT')
    if name == pk and typ == int: pg_typ = 'SERIAL'
    parts = [f'"{name}"', pg_typ]
    if name == pk: parts.append('PRIMARY KEY')
    elif not_null and name in not_null: parts.append('NOT NULL')
    return ' '.join(parts)

# %% ../nbs/00_core.ipynb #2c17673d
@patch
async def create(self:Database, cls=None, name=None, pk='id', foreign_keys=None, defaults=None, 
                 column_order=None, not_null=None, if_not_exists=False, replace=False):
    "Create table from `cls`"
    flexiclass(cls)
    if name is None: name = camel2snake(cls.__name__)
    typs = {o.name: o.type for o in fields(cls)}
    if column_order: typs = {k: typs[k] for k in column_order if k in typs}
    
    cols = [col_def(k, v, pk, not_null) for k, v in typs.items()]
    if defaults:
        for i, (k, v) in enumerate(typs.items()):
            if k in defaults: cols[i] += f' DEFAULT {defaults[k]!r}'
    if foreign_keys:
        for col, (ref_tbl, ref_col) in foreign_keys.items():
            cols.append(f'FOREIGN KEY ("{col}") REFERENCES "{ref_tbl}" ("{ref_col}")')
    
    col_sql = ', '.join(cols)
    exists = 'IF NOT EXISTS ' if if_not_exists else ''
    if replace: await self.execute(f'DROP TABLE IF EXISTS "{name}" CASCADE')
    await self.execute(f'CREATE TABLE {exists}"{name}" ( {col_sql} )')
    tbl = await self._retr_tbl(name)
    tbl.cls = cls
    return tbl

# %% ../nbs/00_core.ipynb #de113b34
@patch
async def drop(self:Table, cascade=False):
    "Drop this table"
    casc = ' CASCADE' if cascade else ''
    await self.db.execute(f'DROP TABLE IF EXISTS {self}{casc}')
    await self.db.refresh()

# %% ../nbs/00_core.ipynb #c5b5bd8f
@patch
async def upsert(self:Table, record=None, **kwargs):
    "Insert or update a row and return it"
    row, cols, vals = _prep_row(record, {**kwargs, **self.xtra_id})
    if not row: return None
    pk = self.pks[0]
    updates = ', '.join(f'"{k}"=EXCLUDED."{k}"' for k in row if k != pk)
    sql = f'INSERT INTO {self} ({cols}) VALUES ({vals}) ON CONFLICT ("{pk}") DO UPDATE SET {updates} RETURNING *'
    return await self._exec_returning(sql, *row.values())

# %% ../nbs/00_core.ipynb #6be00990
async def create_pool(*args, **kwargs):
    kwargs.setdefault('record_class', FRecord)
    kwargs.setdefault('init', setup_json)
    pool = await asyncpg.create_pool(*args, **kwargs)
    res = Database(pool, refresh=False)
    await res.refresh()
    return res
